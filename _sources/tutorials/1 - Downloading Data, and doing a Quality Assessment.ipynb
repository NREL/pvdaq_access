{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Downloading Data, and doing a Quality Assessment\n",
    "\n",
    "**Objectives:**\n",
    "1. Install software\n",
    "2. Donwload dataset\n",
    "3. Run a clear-sky pvanalytics routine (or other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running on google colab, uncomment the next line and execute this cell to install the dependencies and prevent \"ModuleNotFoundError\" in later cells:\n",
    "# Dev branch example: !pip install git+https://github.com/NREL/PV_ICE.git@development\n",
    "!pip install -r https://raw.githubusercontent.com/NREL/pvdaq_access/main/requirements.txt\n",
    "!pip install pvanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvanalytics\n",
    "pvanalytics.__version__\n",
    "from pvanalytics.features.clearsky import reno       #update to just do a pvanalytics import?\n",
    "import pvlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pathlib  # this might not be needed as working on same directory as data here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This information helps with debugging and getting support :)\n",
    "import sys, platform\n",
    "print(\"Working on a \", platform.system(), platform.release())\n",
    "print(\"Python version \", sys.version)\n",
    "print(\"Pandas version \", pd.__version__)\n",
    "print(\"PVlib version \", pvlib.__version__)\n",
    "print(\"pvanalytics version \", pvanalytics.__version__)\n",
    "print(\"pvdaq_access version \", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfolder = 'Tuesday'\n",
    "\n",
    "if not os.path.exists(testfolder):\n",
    "    os.makedirs(testfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pvdaq Script :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "import argparse\n",
    "from botocore.handlers import disable_signing\n",
    "import pandas as pd\n",
    "\n",
    "#---------------------------------------------------------------------------   \n",
    "def downloadSolarPrizeData(system_id, path, file_type='csv'):\n",
    "    '''\n",
    "    Method to access and pull Solar Data Bounty Prize datasets from \n",
    "    the OEDI Data Lake for PVDAQ\n",
    "    Parameters:\n",
    "    -----------------------\n",
    "    system_id : str - system id value found from query of Solar Data Prize systems \n",
    "    available .\n",
    "    path : str - local system location files are to be stored in.\n",
    "    file_type : str - default is .csv, but parquet canbe passed in as option\n",
    "    \n",
    "    Returns\n",
    "    -----------------------\n",
    "    void\n",
    "    \n",
    "    '''\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    s3.meta.client.meta.events.register(\"choose-signer.s3.*\", disable_signing)\n",
    "    bucket = s3.Bucket(\"oedi-data-lake\")\n",
    "    \n",
    "    #Find each target file in buckets\n",
    "    target_dir = system_id + '_OEDI'\n",
    "    prefix =  \"pvdaq/2023-solar-data-prize/\" +  target_dir + \"/data/\"\n",
    "    objects = bucket.objects.filter(Prefix=prefix)\n",
    "    \n",
    "    for obj in objects:\n",
    "        if obj.key == prefix:\n",
    "            continue            \n",
    "        try:\n",
    "            bucket.download_file(obj.key, os.path.join(path, os.path.basename(obj.key)).replace(\"\\\\\", \"/\"))\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            print ('ERROR: Boto3 exception ' + str(e))\n",
    "        else:\n",
    "            print ('File ' + os.path.join(path, os.path.basename(obj.key)) + \" downloaded successfully.\")\n",
    "            \n",
    "    return\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------   \n",
    "def downloadData(system_id, path, file_type='csv'):\n",
    "    '''\n",
    "    Method to access and pull data from the OEDI Data Lake for PVDAQ\n",
    "    Parameters:\n",
    "    -----------------------\n",
    "    system_id : str - system id value found from query of OEDI PVDAQ queue \n",
    "    of available .\n",
    "    path : str - local system location files are to be stored in.\n",
    "    file_type : str - default is .csv, but parquet canbe passed in as option\n",
    "    \n",
    "    Returns\n",
    "    -----------------------\n",
    "    void\n",
    "    \n",
    "    '''\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    s3.meta.client.meta.events.register(\"choose-signer.s3.*\", disable_signing)\n",
    "    bucket = s3.Bucket(\"oedi-data-lake\")\n",
    "    \n",
    "    #Find each target file in buckets\n",
    "    objects = bucket.objects.filter(\n",
    "        Prefix=\"pvdaq/\" + file_type + \"/pvdata/system_id=\" + system_id )\n",
    "    \n",
    "    for obj in objects:\n",
    "        try:\n",
    "            bucket.download_file(obj.key, os.path.join(path, os.path.basename(obj.key)))\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            print ('ERROR: Boto3 exception ' + str(e))\n",
    "        else:\n",
    "            print ('File ' + os.path.join(path, os.path.basename(obj.key)) + \" downloaded successfully.\")\n",
    "            \n",
    "    return\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------   \n",
    "def concatenateData(system_id, path):\n",
    "    '''\n",
    "    Method to merge the multiple files coming in from OEDI\n",
    "    Parameters:\n",
    "    -----------------------\n",
    "    system_id : str - system id value found from query of OEDI PVDAQ queue \n",
    "    of available .\n",
    "    path : str - local system location files are to be stored in.\n",
    "    \n",
    "    Returns\n",
    "    -----------------------\n",
    "    void\n",
    "    \n",
    "    '''\n",
    "    dfs = []\n",
    "    #get list of files in directory\n",
    "    file_list=os.listdir(path)\n",
    "    column_name = 'sensor_name'\n",
    "    #Build a dataframe from current file\n",
    "    print (\"Starting data extraction\")\n",
    "    for file in file_list:\n",
    "        print(\"Extracting file \" + file)\n",
    "        df_file= pd.read_csv(path + '/' + file)\n",
    "        dfs.append(df_file)\n",
    "         \n",
    "    #Build the master data frame from the assembled individual frames.\n",
    "    print (\"Concatenating all files\")\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    target_outputfile = path + \"/system_\" + system_id + \"_data.csv\"\n",
    "    print (\"File is \" + target_outputfile)\n",
    "    df.to_csv(target_outputfile, sep=\",\", index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually running now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\" ..: Starting data access script for PVDAQ OEDI datasets :..\")\n",
    "\n",
    "#Get parameters from command line\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-system', type=str,  help=\"Target system ID\")\n",
    "parser.add_argument('-path', type=str,  help=\"Location to store files locally\")\n",
    "parser.add_argument('-parquet', help=\"Access parquet files (default is .csv)\", action=\"store_true\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.system:\n",
    "    input_string = input(\"Are you accessing data from the DOE Solar Data Bounty Prize: (Y/N): \")\n",
    "    #Handle Solar Data Bounty Prize archives\n",
    "    if input_string.lower() == 'y':\n",
    "        downloadSolarPrizeData(args.system, args.path, file_type='csv')\n",
    "        quit()\n",
    "\n",
    "    else:   #Normal PVDAQ archives\n",
    "        if args.parquet:\n",
    "            downloadData(args.system, args.path, file_type='parquet')\n",
    "        else:\n",
    "            downloadData(args.system, args.path)\n",
    "            #Create single file from data\n",
    "            input_string = input(\"Do you wish to concatenate the files (Y/N): \") \n",
    "            if input_string.lower() == 'y':\n",
    "                concatenateData(args.system, args.path)\n",
    "else:\n",
    "    print('Missing system_id, Exiting.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Look at the data\n",
    "\n",
    "just one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Do PVAnalytics Clear-Sky Detection\n",
    "\n",
    "Identifying periods of clear-sky conditions using measured irradiance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying and filtering for clear-sky conditions is a useful way to\n",
    "reduce noise when analyzing measured data.  This example shows how to\n",
    "use :py:func:`pvanalytics.features.clearsky.reno` to identify clear-sky\n",
    "conditions using measured GHI data.  For this example we'll use\n",
    "GHI measurements downloaded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvanalytics\n",
    "from pvanalytics.features.clearsky import reno\n",
    "import pvlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read in the GHI measurements.  For this example we'll use an example\n",
    "file included in pvanalytics covering a single day, but the same process\n",
    "applies to data of any length.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvanalytics_dir = pathlib.Path(pvanalytics.__file__).parent\n",
    "ghi_file = pvanalytics_dir / 'data' / 'midc_bms_ghi_20220120.csv'\n",
    "data = pd.read_csv(ghi_file, index_col=0, parse_dates=True)\n",
    "\n",
    "# or you can fetch the data straight from the source using pvlib:\n",
    "# date = pd.to_datetime('2022-01-20')\n",
    "# data = pvlib.iotools.read_midc_raw_data_from_nrel('BMS', date, date)\n",
    "\n",
    "measured_ghi = data['Global CMP22 (vent/cor) [W/m^2]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now model clear-sky irradiance for the location and times of the\n",
    "measured data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = pvlib.location.Location(39.742, -105.18)\n",
    "clearsky = location.get_clearsky(data.index)\n",
    "clearsky_ghi = clearsky['ghi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use :py:func:`pvanalytics.features.clearsky.reno` to identify\n",
    "measurements during clear-sky conditions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_clearsky = reno(measured_ghi, clearsky_ghi)\n",
    "\n",
    "# clear-sky times indicated in black\n",
    "measured_ghi.plot()\n",
    "measured_ghi[is_clearsky].plot(ls='', marker='o', ms=2, c='k')\n",
    "plt.ylabel('Global Horizontal Irradiance [W/m2]')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "14c04630f1cd445b2532d35c77825134bfcafda47af70d0b9c2b5023b1f357a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
